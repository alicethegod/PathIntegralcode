{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Scaling Experiment: A Thermodynamic Perspective\n",
    "\n",
    "## Core Functionality & Visualization\n",
    "This script analyzes the D-Scaling phenomenon through the lens of the Path Integral Physics Theory. It integrates **reducible metrics calculation** for high-quality curve fitting and uses a visualization style that emulates top-tier academic conference publications.\n",
    "\n",
    "1.  **Loss Trend**: Tracks and fits the reducible component of the final test loss (Power Law).\n",
    "2.  **Cognitive Internal Energy (U) Trend**: Tracks and fits the reducible component of the system's internal energy (Power Law).\n",
    "3.  **Cognitive Entropy (S) Trend**: Tracks and fits the reducible component of the system's entropy (Exponential Decay).\n",
    "4.  **U/F Ratio Trend**: Calculates and plots the ratio of Cognitive Internal Energy (U) to Cognitive Free Energy (F), which is now directly computed. This ratio serves as a computable proxy for Kolmogorov Complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dataset is available locally.\n",
    "from torchvision import datasets, transforms\n",
    "try:\n",
    "    datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "    datasets.FashionMNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "    print(\"FashionMNIST dataset is ready.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not download dataset. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the experiment's directory to the Python path\n",
    "workspace_path = \".\" # Please adjust this path according to your setup\n",
    "if workspace_path not in sys.path:\n",
    "    sys.path.append(workspace_path)\n",
    "    print(f\"Added path: {workspace_path}\")\n",
    "else:\n",
    "    print(f\"Path {workspace_path} is already in the Python path\")\n",
    "\n",
    "# Confirm the existence of the logic module file\n",
    "file_path = os.path.join(workspace_path, \"VIT_D_logic.py\") # Find and replace with the logic module for the desired model\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"✓ File exists: {file_path}\")\n",
    "else:\n",
    "    print(f\"✗ File not found: {file_path}\")\n",
    "\n",
    "# Attempt to import the module\n",
    "try:\n",
    "    import VIT_D_logic # Replace with the logic module for the desired model\n",
    "    print(\"✓ Module imported successfully!\")\n",
    "    \n",
    "    # Check for the presence of the necessary function\n",
    "    if hasattr(VIT_D_logic, 'run_training_task'):\n",
    "        print(\"✓ Found function: run_training_task\")\n",
    "        run_training_task = VIT_D_logic.run_training_task\n",
    "    else:\n",
    "        print(\"✗ Function not found: run_training_task\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import failed: {e}\")\n",
    "    print(\"Attempting alternative import method...\")\n",
    "    \n",
    "    # Use importlib as a fallback\n",
    "    try:\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\"VIT_D_logic\", file_path)\n",
    "        VIT_D_logic = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(VIT_D_logic)\n",
    "        print(\"✓ Successfully imported using importlib\")\n",
    "\n",
    "        if hasattr(VIT_D_logic, 'run_training_task'):\n",
    "            print(\"✓ Found function: run_training_task\")\n",
    "            run_training_task = VIT_D_logic.run_training_task\n",
    "        else:\n",
    "            print(\"✗ Function not found: run_training_task\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Alternative import also failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Experiment Configuration ---\n",
    "EXPERIMENT_CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 60,\n",
    "    \"d_values\": np.logspace(2.5, 4.7, 25).astype(int),\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"analysis_sample_size\": 30,\n",
    "    \"num_points_for_baseline_estimation\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import linregress\n",
    "import torch\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tasks = [(EXPERIMENT_CONFIG['seed'], d, EXPERIMENT_CONFIG, 0 if torch.cuda.is_available() else -1) for d in EXPERIMENT_CONFIG['d_values']]\n",
    "    results = []\n",
    "    for task_args in tqdm(tasks, desc=f\"Running D-Scaling (Seed {EXPERIMENT_CONFIG['seed']}, Epochs {EXPERIMENT_CONFIG['epochs']})\"):\n",
    "        result = run_training_task(task_args)\n",
    "        if result: results.append(result)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results were generated. Please check the setup.\")\n",
    "    else:\n",
    "        df = pd.DataFrame(results).sort_values('data_size_d')\n",
    "\n",
    "        # --- Calculate Reducible Metrics (Correct Original Logic) ---\n",
    "        n_est = EXPERIMENT_CONFIG['num_points_for_baseline_estimation']\n",
    "        L_inf = df['final_test_loss'].tail(n_est).mean()\n",
    "        df['reducible_loss'] = df['final_test_loss'] - L_inf\n",
    "        U_0 = df['final_U'].head(n_est).mean()\n",
    "        df['reducible_U'] = df['final_U'] - U_0\n",
    "        S_inf = df['final_S'].tail(n_est).mean()\n",
    "        df['reducible_S'] = df['final_S'] - S_inf\n",
    "        df['U_F_ratio'] = df['final_U'] / df['final_F']\n",
    "\n",
    "        # --- Visualization (Conference Style) ---\n",
    "        plt.style.use('seaborn-v0_8-paper')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif', 'font.serif': ['Times New Roman'],\n",
    "            'axes.labelsize': 14, 'xtick.labelsize': 12, 'ytick.labelsize': 12,\n",
    "            'legend.fontsize': 12, 'figure.titlesize': 20, 'mathtext.fontset': 'cm'\n",
    "        })\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(26, 6.5))\n",
    "        fig.suptitle(f'Thermodynamic Analysis of D-Scaling (Seed={EXPERIMENT_CONFIG[\"seed\"]})', y=1.03)\n",
    "\n",
    "        x_d = df['data_size_d'].values\n",
    "        colors = {'loss': '#003f5c', 'U': '#58508d', 'S': '#bc5090', 'ratio': '#ff6361', 'fit': '#ffa600'}\n",
    "        \n",
    "        # --- Fitting Functions ---\n",
    "        def power_law_fit(x, y):\n",
    "            mask = (y > 0) & (x > 0) & np.isfinite(y) & np.isfinite(x)\n",
    "            if mask.sum() < 2: return 0, 1, 0, np.full_like(x, np.nan, dtype=float)\n",
    "            log_x, log_y = np.log10(x[mask]), np.log10(y[mask])\n",
    "            s, i, r, p, _ = linregress(log_x, log_y); r2 = r**2\n",
    "            return r2, p, s, 10**(s*np.log10(x)+i)\n",
    "        \n",
    "        def exp_decay_fit(x, y):\n",
    "            mask = (y > 0) & (x > 0) & np.isfinite(y) & np.isfinite(x)\n",
    "            if mask.sum() < 2: return 0, 1, 0, np.full_like(x, np.nan, dtype=float)\n",
    "            log_y = np.log(y[mask])\n",
    "            slope, intercept, r, p, _ = linregress(x[mask], log_y);\n",
    "            r2 = r**2\n",
    "            decay_rate = -slope\n",
    "            fit = np.exp(slope * x + intercept)\n",
    "            return r2, p, decay_rate, fit\n",
    "\n",
    "        # Plot 1: Loss Trend\n",
    "        r2, p, s, fit = power_law_fit(x_d, df['reducible_loss'])\n",
    "        axes[0].plot(x_d, df['final_test_loss'], 'o', color=colors['loss'], markersize=5)\n",
    "        axes[0].plot(x_d, fit + L_inf, '--', color=colors['fit'], lw=2)\n",
    "        axes[0].set_title('Performance Scaling')\n",
    "        axes[0].set_ylabel('Final Test Loss')\n",
    "        axes[0].text(0.95, 0.95, f'$R^2={r2:.2f}, p={p:.1e}$\\n$L-L_\\infty \\propto D^{{{s:.2f}}}$', ha='right', va='top', transform=axes[0].transAxes, bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.7))\n",
    "\n",
    "        # Plot 2: Cognitive Internal Energy (U) Trend\n",
    "        r2, p, s, fit = power_law_fit(x_d, df['reducible_U'])\n",
    "        axes[1].plot(x_d, df['final_U'], 's', color=colors['U'], markersize=5)\n",
    "        axes[1].plot(x_d, fit + U_0, '--', color=colors['fit'], lw=2)\n",
    "        axes[1].set_title('Internal Energy Scaling')\n",
    "        axes[1].set_ylabel('Cognitive Internal Energy ($U$)')\n",
    "        axes[1].text(0.95, 0.05, f'$R^2={r2:.2f}, p={p:.1e}$\\n$U-U_0 \\propto D^{{{s:.2f}}}$', ha='right', va='bottom', transform=axes[1].transAxes, bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.7))\n",
    "\n",
    "        # Plot 3: Cognitive Entropy (S) Trend - Scatter points, fit curve only\n",
    "        r2, p, decay_rate, fit = exp_decay_fit(x_d, df['reducible_S'])\n",
    "        axes[2].plot(x_d, df['final_S'], '^', color=colors['S'], markersize=5, linestyle='None') # MODIFIED HERE\n",
    "        axes[2].plot(x_d, fit + S_inf, '--', color=colors['fit'], lw=2)\n",
    "        axes[2].set_title('Entropy Scaling')\n",
    "        axes[2].set_ylabel('Cognitive Entropy ($S$)')\n",
    "        axes[2].text(0.95, 0.95, f'$R^2={r2:.2f}, p={p:.1e}$\\n$S-S_\\infty \\propto e^{{-{decay_rate:.1e}D}}$', ha='right', va='top', transform=axes[2].transAxes, bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.7))\n",
    "\n",
    "        # Plot 4: U/F Ratio Trend\n",
    "        axes[3].plot(x_d, df['U_F_ratio'], 'd-', color=colors['ratio'], markersize=5, lw=1.5)\n",
    "        axes[3].set_title('K-Complexity Proxy Scaling')\n",
    "        axes[3].set_ylabel(r'U/F Ratio ($U / F$)')\n",
    "        axes[3].axhline(0, color='grey', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        # --- Final Formatting ---\n",
    "        for ax in axes:\n",
    "            ax.set_xlabel('Dataset Size ($D$)')\n",
    "            ax.set_xscale('log')\n",
    "            ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        axes[0].set_yscale('log'); axes[1].set_yscale('log'); axes[2].set_yscale('log'); axes[3].set_yscale('linear')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        \n",
    "        # --- Save results ---\n",
    "        output_dir = 'results_final'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        file_prefix = f\"d_scaling_final_seed_{EXPERIMENT_CONFIG['seed']}_epochs_{EXPERIMENT_CONFIG['epochs']}\"\n",
    "        output_img_path = os.path.join(output_dir, f\"{file_prefix}.png\")\n",
    "        output_csv_path = os.path.join(output_dir, f\"{file_prefix}.csv\")\n",
    "        \n",
    "        plt.savefig(output_img_path, dpi=300, bbox_inches='tight')\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        \n",
    "        print(f\"Plot saved to: {output_img_path}\")\n",
    "        print(f\"Experiment data saved to: {output_csv_path}\")\n",
    "        \n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
