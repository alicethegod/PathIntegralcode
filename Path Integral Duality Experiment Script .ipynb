{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Integral Physics Theory: U-S Duality Experiment (Harmonic Mean Proxy)\n",
    "\n",
    "This script aims to experimentally validate the **Grounding Duality** corollary of our path integral physics theory. \n",
    "\n",
    "This version reverts to using the **harmonic mean of path energies** as a stable and regular proxy for the Cognitive Internal Energy (U), which is equivalent to the original $H'_{TSE}$ metric. This allows for a clearer visualization of the underlying dynamics. The Cognitive Entropy (S) remains the Shannon entropy of path importances, equivalent to the original $H'_{SIE}$.\n",
    "\n",
    "The experiment will focus on:\n",
    "\n",
    "1.  **Observing the Dynamics of U (proxy) and S**: Tracking the evolution of our stable U proxy and S over time for both input (Forward) and output (Backward) grounding modes.\n",
    "2.  **Validating the U-S Linear Relationship**: Plotting U vs. S to confirm their linear relationship.\n",
    "3.  **Quantifying the Trends**: Fitting the dynamics with logarithmic functions and reporting RÂ² and p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import copy\n",
    "import warnings\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# --- 1. Experiment Configuration ---\n",
    "N_SAMPLES = 2000\n",
    "N_EPOCHS = 5000\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.05\n",
    "ANALYSIS_SAMPLE_SIZE = 30\n",
    "LOG_INTERVAL = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. MLP Model Definition ---\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Preparation ---\n",
    "X, y = make_moons(n_samples=N_SAMPLES, noise=0.1, random_state=42)\n",
    "X = torch.FloatTensor(X).to(DEVICE)\n",
    "y = torch.LongTensor(y).to(DEVICE)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Path Integral Physics Theory Analyzer (Original Stable Version) ---\n",
    "class PathIntegralAnalyzer:\n",
    "    def __init__(self, model, grounding_mode='output'):\n",
    "        model_copy = copy.deepcopy(model)\n",
    "        model_copy.eval()\n",
    "        self.model = model_copy.to('cpu')\n",
    "        \n",
    "        if grounding_mode not in ['input', 'output']:\n",
    "            raise ValueError(\"grounding_mode must be 'input' or 'output'\")\n",
    "        self.grounding_mode = grounding_mode\n",
    "        \n",
    "        self.graph, self.layer_map = self._build_graph()\n",
    "        self.grounding_nodes = self._get_grounding_nodes()\n",
    "        self.hidden_nodes = self._get_hidden_nodes()\n",
    "        self.memoized_paths = {}\n",
    "\n",
    "    def _build_graph(self):\n",
    "        G = nx.DiGraph()\n",
    "        node_counter = 0\n",
    "        layer_map = {}\n",
    "        linear_layers = [l for l in self.model.layers if isinstance(l, nn.Linear)]\n",
    "\n",
    "        in_features = linear_layers[0].in_features\n",
    "        layer_map[0] = list(range(node_counter, node_counter + in_features))\n",
    "        for _ in range(in_features):\n",
    "            G.add_node(node_counter, layer=0); node_counter += 1\n",
    "\n",
    "        graph_layer_idx = 1\n",
    "        for l in linear_layers:\n",
    "            layer_map[graph_layer_idx] = list(range(node_counter, node_counter + l.out_features))\n",
    "            for _ in range(l.out_features):\n",
    "                G.add_node(node_counter, layer=graph_layer_idx); node_counter += 1\n",
    "            \n",
    "            weights = torch.abs(l.weight.data.t())\n",
    "            probs = torch.softmax(weights, dim=1)\n",
    "            \n",
    "            for u_local_idx, u_global_idx in enumerate(layer_map[graph_layer_idx - 1]):\n",
    "                for v_local_idx, v_global_idx in enumerate(layer_map[graph_layer_idx]):\n",
    "                    prob = probs[u_local_idx, v_local_idx].item()\n",
    "                    if prob > 1e-9:\n",
    "                        # The term 'cost' is used here to represent energy for the harmonic mean calculation\n",
    "                        G.add_edge(u_global_idx, v_global_idx, cost=1.0 - np.log(prob + 1e-9))\n",
    "            graph_layer_idx += 1\n",
    "        return G, layer_map\n",
    "\n",
    "    def _get_grounding_nodes(self):\n",
    "        if self.grounding_mode == 'input':\n",
    "            return set(self.layer_map[0])\n",
    "        else: # 'output'\n",
    "            max_layer_idx = max(self.layer_map.keys())\n",
    "            return set(self.layer_map[max_layer_idx])\n",
    "\n",
    "    def _get_hidden_nodes(self):\n",
    "        max_layer_idx = max(self.layer_map.keys())\n",
    "        return [node for node, data in self.graph.nodes(data=True) if data['layer'] not in [0, max_layer_idx]]\n",
    "\n",
    "    def find_all_paths(self, start, targets):\n",
    "        # For 'input' grounding, search backward on the graph\n",
    "        G_search = self.graph.reverse() if self.grounding_mode == 'input' else self.graph\n",
    "        memo_key = (start, tuple(sorted(list(targets))))\n",
    "        if memo_key in self.memoized_paths: return self.memoized_paths[memo_key]\n",
    "        \n",
    "        paths = []\n",
    "        for target in targets:\n",
    "            try:\n",
    "                for path in nx.all_simple_paths(G_search, source=start, target=target, cutoff=10):\n",
    "                    cost = sum(G_search.get_edge_data(u, v)['cost'] for u, v in zip(path, path[1:]))\n",
    "                    paths.append({'path': path, 'cost': cost})\n",
    "            except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "                continue\n",
    "        \n",
    "        self.memoized_paths[memo_key] = paths\n",
    "        return paths\n",
    "\n",
    "    def calculate_physics_for_node(self, node):\n",
    "        paths = self.find_all_paths(node, self.grounding_nodes)\n",
    "        if not paths:\n",
    "            return {'U': float('inf'), 'S': float('nan')}\n",
    "\n",
    "        costs = np.array([p['cost'] for p in paths])\n",
    "        \n",
    "        # U: Cognitive Internal Energy (Proxy using harmonic mean of costs/energies)\n",
    "        conductances = 1.0 / (costs + 1e-9)\n",
    "        U = 1.0 / np.sum(conductances) if np.sum(conductances) > 0 else float('inf')\n",
    "\n",
    "        # S: Cognitive Entropy (Shannon Entropy of path importances)\n",
    "        importances = np.exp(-1.0 * costs)\n",
    "        probabilities = importances / np.sum(importances) if np.sum(importances) > 0 else np.zeros_like(importances)\n",
    "        S = -np.sum(probabilities * np.log2(probabilities + 1e-9))\n",
    "        \n",
    "        return {'U': U, 'S': S}\n",
    "\n",
    "    def analyze_network(self, sample_size):\n",
    "        U_vals, S_vals = [], []\n",
    "        if not self.hidden_nodes: return float('inf'), float('nan')\n",
    "\n",
    "        sample_nodes = np.random.choice(self.hidden_nodes, size=min(sample_size, len(self.hidden_nodes)), replace=False)\n",
    "        for node in sample_nodes:\n",
    "            physics = self.calculate_physics_for_node(node)\n",
    "            if np.isfinite(physics['U']) and np.isfinite(physics['S']):\n",
    "                U_vals.append(physics['U'])\n",
    "                S_vals.append(physics['S'])\n",
    "                \n",
    "        mean_U = np.mean(U_vals) if U_vals else float('inf')\n",
    "        mean_S = np.mean(S_vals) if S_vals else float('nan')\n",
    "        \n",
    "        return mean_U, mean_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Training and Logging Physical Quantities (U and S) ---\n",
    "model = SimpleMLP(input_dim=2, hidden_dim1=10, hidden_dim2=7, output_dim=2).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "history = {\n",
    "    'epochs': [],\n",
    "    'loss': [],\n",
    "    'U_forward': [], 'S_forward': [], # Forward (input grounding) analysis\n",
    "    'U_backward': [], 'S_backward': []  # Backward (output grounding) analysis\n",
    "}\n",
    "\n",
    "pbar = trange(N_EPOCHS, desc=\"Training\")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % LOG_INTERVAL == 0:\n",
    "        history['epochs'].append(epoch)\n",
    "        history['loss'].append(loss.item())\n",
    "        \n",
    "        # Forward analysis (Theoretical Basis)\n",
    "        analyzer_forward = PathIntegralAnalyzer(model, grounding_mode='input')\n",
    "        U_fwd, S_fwd = analyzer_forward.analyze_network(ANALYSIS_SAMPLE_SIZE)\n",
    "        history['U_forward'].append(U_fwd)\n",
    "        history['S_forward'].append(S_fwd)\n",
    "\n",
    "        # Backward analysis (Engineering Proxy)\n",
    "        analyzer_backward = PathIntegralAnalyzer(model, grounding_mode='output')\n",
    "        U_bwd, S_bwd = analyzer_backward.analyze_network(ANALYSIS_SAMPLE_SIZE)\n",
    "        history['U_backward'].append(U_bwd)\n",
    "        history['S_backward'].append(S_bwd)\n",
    "        \n",
    "        pbar.set_postfix_str(f\"Loss:{loss.item():.3f} | U_fwd:{U_fwd:.2f} | U_bwd:{U_bwd:.2f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Visualization and Statistical Analysis of Results (Modified) ---\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(22, 20))\n",
    "fig.suptitle('Path Integral Duality Experiment: U-S Dynamics Analysis (Stable Proxy)', fontsize=24, y=0.98)\n",
    "\n",
    "# --- Data Cleaning ---\n",
    "epochs = np.array(history['epochs'])\n",
    "U_fwd = np.array(history['U_forward'])\n",
    "S_fwd = np.array(history['S_forward'])\n",
    "U_bwd = np.array(history['U_backward'])\n",
    "S_bwd = np.array(history['S_backward'])\n",
    "\n",
    "mask_fwd = np.isfinite(U_fwd) & np.isfinite(S_fwd) & (epochs > 0) # Exclude epoch 0 for log fit\n",
    "mask_bwd = np.isfinite(U_bwd) & np.isfinite(S_bwd) & (epochs > 0)\n",
    "\n",
    "# --- Fitting Functions ---\n",
    "def log_func(x, a, b, c):\n",
    "    return a * np.log(b * x + 1) + c\n",
    "\n",
    "# --- Plot 1: U-S Linear Relationship ---\n",
    "# Forward Analysis\n",
    "slope_fwd, intercept_fwd, r_fwd, p_fwd, _ = linregress(S_fwd[mask_fwd], U_fwd[mask_fwd])\n",
    "axes[0, 0].scatter(S_fwd[mask_fwd], U_fwd[mask_fwd], label='Forward Data', color='C0', alpha=0.7, s=50)\n",
    "axes[0, 0].plot(S_fwd[mask_fwd], intercept_fwd + slope_fwd * S_fwd[mask_fwd], color='C0', linestyle='--', lw=2.5)\n",
    "axes[0, 0].set_title('Forward Analysis (Input Grounding): U vs. S', fontsize=18)\n",
    "axes[0, 0].set_xlabel(\"Cognitive Entropy (S)\", fontsize=14)\n",
    "axes[0, 0].set_ylabel(\"Cognitive Internal Energy (U) - Proxy\", fontsize=14)\n",
    "axes[0, 0].text(0.95, 0.95, f'$R^2 = {r_fwd**2:.4f}$\\n$p = {p_fwd:.2e}$', transform=axes[0, 0].transAxes, fontsize=14, va='top', ha='right', bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', alpha=0.8))\n",
    "axes[0, 0].legend(fontsize=12)\n",
    "\n",
    "# Backward Analysis\n",
    "slope_bwd, intercept_bwd, r_bwd, p_bwd, _ = linregress(S_bwd[mask_bwd], U_bwd[mask_bwd])\n",
    "axes[0, 1].scatter(S_bwd[mask_bwd], U_bwd[mask_bwd], label='Backward Data', color='C3', alpha=0.7, s=50)\n",
    "axes[0, 1].plot(S_bwd[mask_bwd], intercept_bwd + slope_bwd * S_bwd[mask_bwd], color='C3', linestyle='--', lw=2.5)\n",
    "axes[0, 1].set_title('Backward Analysis (Output Grounding): U vs. S', fontsize=18)\n",
    "axes[0, 1].set_xlabel(\"Cognitive Entropy (S)\", fontsize=14)\n",
    "axes[0, 1].set_ylabel(\"Cognitive Internal Energy (U) - Proxy\", fontsize=14)\n",
    "axes[0, 1].text(0.95, 0.95, f'$R^2 = {r_bwd**2:.4f}$\\n$p = {p_bwd:.2e}$', transform=axes[0, 1].transAxes, fontsize=14, va='top', ha='right', bbox=dict(boxstyle='round,pad=0.5', fc='seashell', alpha=0.8))\n",
    "axes[0, 1].legend(fontsize=12)\n",
    "\n",
    "# --- Plot 2: Dynamics Over Time with Logarithmic Fit ---\n",
    "# Forward Dynamics\n",
    "ax_fwd_U = axes[1, 0]\n",
    "ax_fwd_S = ax_fwd_U.twinx()\n",
    "p_fwd_U, = ax_fwd_U.plot(epochs[mask_fwd], U_fwd[mask_fwd], 'o', label='U_forward (Cost)', color='C0', alpha=0.5)\n",
    "p_fwd_S, = ax_fwd_S.plot(epochs[mask_fwd], S_fwd[mask_fwd], 's', label='S_forward (Robustness)', color='skyblue', alpha=0.5)\n",
    "\n",
    "u_fwd_stats_text = \"U_fwd fit failed\"\n",
    "s_fwd_stats_text = \"S_fwd fit failed\"\n",
    "\n",
    "try:\n",
    "    params_U_fwd, _ = curve_fit(log_func, epochs[mask_fwd], U_fwd[mask_fwd], p0=[1, 0.001, np.min(U_fwd[mask_fwd])], maxfev=5000)\n",
    "    fit_U_fwd = log_func(epochs[mask_fwd], *params_U_fwd)\n",
    "    ax_fwd_U.plot(epochs[mask_fwd], fit_U_fwd, '--', color='navy', lw=2)\n",
    "    _, _, r_u, p_u, _ = linregress(U_fwd[mask_fwd], fit_U_fwd)\n",
    "    u_fwd_stats_text = f\"$R^2={r_u**2:.2f}, p={p_u:.1e}$\"\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    params_S_fwd, _ = curve_fit(log_func, epochs[mask_fwd], S_fwd[mask_fwd], p0=[-1, 0.001, np.max(S_fwd[mask_fwd])], maxfev=5000)\n",
    "    fit_S_fwd = log_func(epochs[mask_fwd], *params_S_fwd)\n",
    "    ax_fwd_S.plot(epochs[mask_fwd], fit_S_fwd, '-.', color='cyan', lw=2)\n",
    "    _, _, r_s, p_s, _ = linregress(S_fwd[mask_fwd], fit_S_fwd)\n",
    "    s_fwd_stats_text = f\"$R^2={r_s**2:.2f}, p={p_s:.1e}$\"\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "ax_fwd_U.set_xlabel('Epoch', fontsize=14)\n",
    "ax_fwd_U.set_ylabel('Cognitive Internal Energy (U)', color='C0', fontsize=14)\n",
    "ax_fwd_S.set_ylabel('Cognitive Entropy (S)', color='skyblue', fontsize=14)\n",
    "ax_fwd_U.set_title('Forward Analysis Dynamics', fontsize=18)\n",
    "ax_fwd_U.legend(handles=[p_fwd_U, p_fwd_S], loc='best', fontsize=12)\n",
    "fwd_text = f\"--- Fit Test ---\\nU(t): {u_fwd_stats_text}\\nS(t): {s_fwd_stats_text}\\n$y \\\\approx a \\\\ln(bt+1)+c$\"\n",
    "ax_fwd_U.text(0.95, 0.05, fwd_text, transform=ax_fwd_U.transAxes, fontsize=12, va='bottom', ha='right', bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', alpha=0.8))\n",
    "\n",
    "# Backward Dynamics\n",
    "ax_bwd_U = axes[1, 1]\n",
    "ax_bwd_S = ax_bwd_U.twinx()\n",
    "p_bwd_U, = ax_bwd_U.plot(epochs[mask_bwd], U_bwd[mask_bwd], 'o', label='U_backward (Cost)', color='C3', alpha=0.5)\n",
    "p_bwd_S, = ax_bwd_S.plot(epochs[mask_bwd], S_bwd[mask_bwd], 's', label='S_backward (Robustness)', color='lightcoral', alpha=0.5)\n",
    "\n",
    "u_bwd_stats_text = \"U_bwd fit failed\"\n",
    "s_bwd_stats_text = \"S_bwd fit failed\"\n",
    "\n",
    "try:\n",
    "    params_U_bwd, _ = curve_fit(log_func, epochs[mask_bwd], U_bwd[mask_bwd], p0=[-1, 0.001, np.max(U_bwd[mask_bwd])], maxfev=5000)\n",
    "    fit_U_bwd = log_func(epochs[mask_bwd], *params_U_bwd)\n",
    "    ax_bwd_U.plot(epochs[mask_bwd], fit_U_bwd, '--', color='darkred', lw=2)\n",
    "    _, _, r_u, p_u, _ = linregress(U_bwd[mask_bwd], fit_U_bwd)\n",
    "    u_bwd_stats_text = f\"$R^2={r_u**2:.2f}, p={p_u:.1e}$\"\n",
    "except RuntimeError:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    params_S_bwd, _ = curve_fit(log_func, epochs[mask_bwd], S_bwd[mask_bwd], p0=[1, 0.001, np.min(S_bwd[mask_bwd])], maxfev=5000)\n",
    "    fit_S_bwd = log_func(epochs[mask_bwd], *params_S_bwd)\n",
    "    ax_bwd_S.plot(epochs[mask_bwd], fit_S_bwd, '-.', color='orange', lw=2)\n",
    "    _, _, r_s, p_s, _ = linregress(S_bwd[mask_bwd], fit_S_bwd)\n",
    "    s_bwd_stats_text = f\"$R^2={r_s**2:.2f}, p={p_s:.1e}$\"\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "ax_bwd_U.set_xlabel('Epoch', fontsize=14)\n",
    "ax_bwd_U.set_ylabel('Cognitive Internal Energy (U)', color='C3', fontsize=14)\n",
    "ax_bwd_S.set_ylabel('Cognitive Entropy (S)', color='lightcoral', fontsize=14)\n",
    "ax_bwd_U.set_title('Backward Analysis Dynamics', fontsize=18)\n",
    "ax_bwd_U.legend(handles=[p_bwd_U, p_bwd_S], loc='best', fontsize=12)\n",
    "bwd_text = f\"--- Fit Test ---\\nU(t): {u_bwd_stats_text}\\nS(t): {s_bwd_stats_text}\\n$y \\\\approx a \\\\ln(bt+1)+c$\"\n",
    "ax_bwd_U.text(0.95, 0.05, bwd_text, transform=ax_bwd_U.transAxes, fontsize=12, va='bottom', ha='right', bbox=dict(boxstyle='round,pad=0.5', fc='seashell', alpha=0.8))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language_info": {
    "name": "python"
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
